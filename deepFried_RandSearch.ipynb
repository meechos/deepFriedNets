{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# deepFried Nets: Model tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/cdsw/Data/EPI/Raw/train_sub1M_imputed_dd.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check for missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "df = df.dropna()\n",
    "df_sample = df.sample(frac=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define feature and target tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ_index = df.columns.get_loc('patient_type')\n",
    "X_sample = df_sample.iloc[:, 1:targ_index].values\n",
    "y_sample = df_sample.iloc[:, -1].values\n",
    "\n",
    "X = df.iloc[:, 1:targ_index].values\n",
    "y = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Class balancing with random undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
    "from collections import Counter\n",
    "\n",
    "sampling_strategy = {1:10}\n",
    "rus = RandomUnderSampler(random_state=0, ratio=0.1)\n",
    "\n",
    "Xsample_resampled, ysample_resampled = rus.fit_resample(X_sample,y_sample)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "print(sorted(Counter(ysample_resampled).items()))\n",
    "\n",
    "y_resampled= pd.get_dummies(y_resampled)\n",
    "ysample_resampled = pd.get_dummies(ysample_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### One hot encode gender \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotencoder = OneHotEncoder(categorical_features=[0])\n",
    "Xsample_resampled = onehotencoder.fit_transform(Xsample_resampled).toarray()\n",
    "X_resampled = onehotencoder.fit_transform(X_resampled).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.33, \n",
    "                                                    shuffle= True)\n",
    "Xsample_train, Xsample_test, ysample_train, ysample_test = train_test_split(Xsample_resampled, \n",
    "                                                                            ysample_resampled, \n",
    "                                                                            test_size=0.33,\n",
    "                                                                            shuffle= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "Xsample_train = scaler.fit_transform(Xsample_train)\n",
    "Xsample_test = scaler.fit_transform(Xsample_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameter and architecture scanning (RandomisedSearchCV)\n",
    "\n",
    "Scan over hyperparameter values using `Keras.wrappers` and a parameter dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.constraints import unit_norm\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import SGD, Adadelta\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, average_precision_score\n",
    "from scipy.stats import randint\n",
    "from sklearn.utils.fixes import loguniform"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model definition\n",
    "\n",
    "Instantiate the model to be used in the `wrapper`. Modify according to the type model and hyperparameter to scan over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_hidden=1, n_neurons=30, learning_rate = 0.01, drop_rate = 0.5, act_func = 'LeakyReLU',\n",
    "                act_func_out = 'sigmoid',kernel_init = 'uniform', opt= 'Adadelta'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_neurons, input_shape=(X_resampled.shape[1],), activation=act_func,\n",
    "                   kernel_initializer = kernel_init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(drop_rate))\n",
    "    # Add as many hidden layers as specified in n_hidden\n",
    "    for layer in range(n_hidden):\n",
    "    # Layers have nn neurons model.add(Dense(nn, activation='relu'\n",
    "        model.add(Dense(n_neurons, activation=act_func, kernel_initializer = kernel_init))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(drop_rate))\n",
    "    model.add(Dense(2, activation=act_func_out, kernel_initializer = kernel_init))\n",
    "    opt= Adadelta(lr=learning_rate)\n",
    "    model.compile(loss='binary_crossentropy',optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model)\n",
    "#kfold = cross_val_score(model, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameter dictionary\n",
    "Optimise for:\n",
    "- number of hidden layers\n",
    "- number of neurons\n",
    "- activation func and optimizers\n",
    "- number of epochs\n",
    "- learning rate\n",
    "- initialisation krnel\n",
    "- batch size\n",
    "- dropout rate\n",
    "\n",
    "Define dictionary and pass a range or set of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(n_hidden=[16, 24, 32, 64, 128],\n",
    "              epochs=[100, 20, 30],\n",
    "              n_neurons=[8, 16, 32, 64, 128, 256, 512],\n",
    "              act_func=['relu'],\n",
    "              act_func_out=['softmax'],\n",
    "              learning_rate= [0.01, 0.1, 0.3, 0.5],\n",
    "              opt = ['adam','Adadelta', 'Adagrad','Rmsprop'],\n",
    "              kernel_init = ['uniform', 'normal', 'glorot_uniform'],\n",
    "              batch_size=[256, 512, 1024, 2048],\n",
    "              drop_rate=[0.1, 0.2, 0.3, 0.5])\n",
    "              #scoring = ['accuracy', 'average_precision']"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RandomizedSearchCV implementation\n",
    "\n",
    "In the dictionary above parameters are presented as lists. it is highly recommended to **use continuous distributions for continuous parameters** using `loguniform` or `randint`, e.g.:\n",
    "\n",
    "```bash\n",
    "    {'C': loguniform(1e0, 1e3),\n",
    "    'gamma': loguniform(1e-4, 1e-3)\n",
    "    }\n",
    "```\n",
    "If all parameters are presented as a list, sampling without replacement is performed. If at least one parameter is given as a distribution, sampling with replacement is used. \n",
    "\n",
    "The number of parameter settings that are tried is given by `n_iter`. For continuous parameters, increasing n_iter will lead to a finer search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(model,  params, n_iter=10, scoring='average_precision', \n",
    "                                   cv=5)\n",
    "\n",
    "# if running on CPUs --> add n_jobs=-1 arg to RandomizedSearchCV\n",
    "random_search_results = random_search.fit(Xsample_train, ysample_train, \n",
    "                                          validation_data =(Xsample_test, ysample_test),\n",
    "                                          callbacks=[EarlyStopping(patience=15)])\n",
    "\n",
    "print('best score (average percision):', random_search_results.best_score_)\n",
    "print('best parameters:',random_search_results.best_params_)"
   ]
  }
 ]
}