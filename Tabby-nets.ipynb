{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rNdWfPXCjTjY"
   },
   "source": [
    "##### Copyright 2019 Faculty Authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c05P9g5WjizZ"
   },
   "source": [
    "# Tabby-nets\n",
    "\n",
    "**TF2.0 Input_fn** for `.csv` or `pd.dataframes` to [TabNet](https://arxiv.org/abs/1908.07442) for Tensorflow 2.0, whose original codebase is available at https://github.com/titu1994/tf-TabNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5IoRbCA2n0_V"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tabnet\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VS4w2LePn9g3"
   },
   "outputs": [],
   "source": [
    "csv_file = 'train.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6BXRPD2-xtQ1"
   },
   "source": [
    "### Read the csv file using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UEfJ8TcMpe-2"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8FkK6QIRpjd4"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ww4lRDCS3qPh"
   },
   "source": [
    "Convert `dtype: object` columns which is to a discrete numerical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LmCl5R5C2IKo"
   },
   "outputs": [],
   "source": [
    "df['pat_gender'] = pd.Categorical(df['pat_gender'])\n",
    "df['pat_gender'] = df.variety.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s4XA1SNW2QyI"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class balancing with random undersampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
    "from collections import Counter\n",
    "rus = RandomUnderSampler(random_state=0, ratio=0.1, return_indices=True)\n",
    "_, _, index = rus.fit_resample(df, df.patient_type)\n",
    "df = df.iloc[index,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale features with `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2wwhILm1ycSp"
   },
   "outputs": [],
   "source": [
    "target_col = 'patient_type'\n",
    "target = df.pop('patient_type')\n",
    "target = pd.get_dummies(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "mapper = DataFrameMapper([(df.columns, StandardScaler())])\n",
    "scaled_features = mapper.fit_transform(df.copy(), 4)\n",
    "scaled_df = pd.DataFrame(scaled_features, index=df.index, columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WWRhH6r4xxQu"
   },
   "source": [
    "## Load data using `tf.data.Dataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GuqmVVH_yApQ"
   },
   "source": [
    "Use `tf.data.Dataset.from_tensor_slices` to read the values from a pandas dataframe. \n",
    "\n",
    "One of the advantages of using `tf.data.Dataset` is it allows you to write simple, highly efficient data pipelines. Read the [loading data guide](https://www.tensorflow.org/guide/data) to find out more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6Yc-D3aqyBb"
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((df.values, target.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YEOpw7LhMYsI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 train examples\n",
      "21 test examples\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, target, test_size=0.2)\n",
    "# train, val = train_test_split(train, test_size=0.2)\n",
    "print(len(X_train), 'train examples')\n",
    "print(len(X_test), 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "chEnp_Swsf0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: [5.1 3.5 1.4 0.2], Target: 0\n",
      "Features: [4.9 3.  1.4 0.2], Target: 0\n",
      "Features: [4.7 3.2 1.3 0.2], Target: 0\n",
      "Features: [4.6 3.1 1.5 0.2], Target: 0\n",
      "Features: [5.  3.6 1.4 0.2], Target: 0\n"
     ]
    }
   ],
   "source": [
    "for feat, targ in dataset.take(5):\n",
    "  print ('Features: {}, Target: {}'.format(feat, targ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GzwlAhX6xH9Q"
   },
   "source": [
    "Since a `pd.Series` implements the `__array__` protocol it can be used transparently nearly anywhere you would use a `np.array` or a `tf.Tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GnpHHkpktl5y"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=114675, shape=(101,), dtype=float64, numpy=\n",
       "array([0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.2, 0.1,\n",
       "       0.1, 0.2, 0.4, 0.4, 0.3, 0.3, 0.3, 0.2, 0.4, 0.2, 0.5, 0.2, 0.2,\n",
       "       0.4, 0.2, 0.2, 0.2, 0.2, 0.4, 0.1, 0.2, 0.2, 0.2, 0.2, 0.1, 0.2,\n",
       "       0.2, 0.3, 0.3, 0.2, 0.6, 0.4, 0.3, 0.2, 0.2, 0.2, 0.2, 1.4, 1.5,\n",
       "       1.5, 1.3, 1.5, 1.3, 1.6, 1. , 1.3, 1.4, 1. , 1.5, 1. , 1.4, 1.3,\n",
       "       1.4, 1.5, 1. , 1.5, 1.1, 1.8, 1.3, 1.5, 1.2, 1.3, 1.4, 1.4, 1.7,\n",
       "       1.5, 1. , 1.1, 1. , 1.2, 1.6, 1.5, 1.6, 1.5, 1.3, 1.3, 1.3, 1.2,\n",
       "       1.4, 1.2, 1. , 1.3, 1.2, 1.3, 1.3, 1.1, 1.3, 2.5])>"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(scaled_df['pat_gocard'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9XLxRHS10Ylp"
   },
   "source": [
    "Shuffle the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R3dQ-83Ztsgl"
   },
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaled_df, target, test_size=0.22)\n",
    "print(len(X_train), 'train examples')\n",
    "print(len(X_test), 'test examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d6V_6F_MBiG9"
   },
   "source": [
    "## Alternative to feature columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qSCN5f_vUURE"
   },
   "source": [
    "The easiest way to preserve the column structure of a `pd.DataFrame` when used with `tf.data` is to convert the `pd.DataFrame` to a `dict`, and slice that dictionary. Batch the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wUjRKgEhPZqK"
   },
   "outputs": [],
   "source": [
    "batch_size = int(len(X_train)*0.1)\n",
    "\n",
    "train_slices = tf.data.Dataset.from_tensor_slices((X_train.to_dict('list'), \n",
    "                                                  y_train)).batch(50)\n",
    "\n",
    "test_slices = tf.data.Dataset.from_tensor_slices((X_test.to_dict('list'), \n",
    "                                                  y_test)).batch(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WWRaiwxeyA9Z"
   },
   "outputs": [],
   "source": [
    "for train_slice in train_slices.take(1):\n",
    "  print (train_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q7OEKe82N-Qb"
   },
   "source": [
    "### Feature columns (numeric)\n",
    "The output of a feature column becomes the input to the model. A [numeric column](https://www.tensorflow.org/api_docs/python/tf/feature_column/numeric_column) is the simplest type of column. It is used to represent real valued features. When using this column, the model will receive the column value from the dataframe unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = list(scaled_df.columns.values)\n",
    "feature_columns = []\n",
    "for col_name in col_names:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(col_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tabnet.TabNetClassification(feature_columns, num_classes=2,\n",
    "                                    feature_dim=32, output_dim=32,\n",
    "                                    num_decision_steps=2, relaxation_factor=1.0,\n",
    "                                    sparsity_coefficient=1e-5, batch_momentum=0.98,\n",
    "                                    virtual_batch_size=None, norm_type='batch',\n",
    "                                    num_groups=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = tf.keras.optimizers.schedules.ExponentialDecay(0.01, decay_steps=100, decay_rate=0.9, staircase=False)\n",
    "optimizer = tf.keras.optimizers.Adam(lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "model.compile(optimizer, loss='categorical_crossentropy', \n",
    "              metrics=['accuracy',  f1_m,precision_m, recall_m]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_slices, epochs=100, validation_data=test_slices, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary\n",
    "Print TabNet custom architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tab_net_classification_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "tab_net_14 (TabNet)          multiple                  208       \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             multiple                  8         \n",
      "=================================================================\n",
      "Total params: 216\n",
      "Trainable params: 216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Save the images of the feature masks\n",
    "Force eager execution mode to generate the masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving mask 1 of shape (1, 16, 4, 1)\n",
      "Saving aggregate mask of shape (1, 16, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print()\n",
    "if os.path.exists('logs/'):\n",
    "    shutil.rmtree('logs/')\n",
    "\n",
    "x, y = next(iter(train_slices))\n",
    "_ = model(x)\n",
    "\n",
    "writer = tf.summary.create_file_writer(\"logs/\")\n",
    "with writer.as_default():\n",
    "    for i, mask in enumerate(model.tabnet.feature_selection_masks):\n",
    "        print(\"Saving mask {} of shape {}\".format(i + 1, mask.shape))\n",
    "        tf.summary.image('mask_at_iter_{}'.format(i + 1), step=0, data=mask, max_outputs=1)\n",
    "        writer.flush()\n",
    "\n",
    "    agg_mask = model.tabnet.aggregate_feature_selection_mask\n",
    "    print(\"Saving aggregate mask of shape\", agg_mask.shape)\n",
    "    tf.summary.image(\"Aggregate Mask\", step=0, data=agg_mask, max_outputs=1)\n",
    "    writer.flush()\n",
    "\n",
    "writer.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_train_preds = model.predict(test_slices)\n",
    "trainset_score = average_precision_score(y_test, tab_train_preds)\n",
    "config.APS_train = trainset_score\n",
    "print('train set average precision score:',trainset_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
